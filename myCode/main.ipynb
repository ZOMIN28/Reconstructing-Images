{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "from myModel import FEN,IRN\n",
    "import torch.optim as optim\n",
    "\n",
    "# set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 1\n",
    "# every batch load 16 pictures\n",
    "batch_size = 16\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_data =torchvision.datasets.ImageFolder(root='ILSVRC2012/train',download=True,transform=data_transform)\\ntrain_data_loader = torch.utils.data.DataLoader(train_data,batch_size=4, shuffle=True,num_workers=1)\\n\\nval_data = torchvision.datasets.ImageFolder(root='ILSVRC2012/val',download=False,transform=data_transform)\\nval_data_loader =  torch.utils.data.DataLoader(val_data,batch_size=4, shuffle=True,num_workers=1)   \\n\\ntest_data = torchvision.datasets.ImageFolder(root='ILSVRC2012/test',download=False,transform=data_transform)\\ntest_data_loader =  torch.utils.data.DataLoader(test_data,batch_size=4, shuffle=True,num_workers=1)  \\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ImageNet dataset\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                    \t     std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_data =torchvision.datasets.ImageFolder(root='ILSVRC2012/train',download=True,transform=data_transform)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data,batch_size=4, shuffle=True,num_workers=1)\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(root='ILSVRC2012/val',download=False,transform=data_transform)\n",
    "val_data_loader =  torch.utils.data.DataLoader(val_data,batch_size=4, shuffle=True,num_workers=1)   \n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root='ILSVRC2012/test',download=False,transform=data_transform)\n",
    "test_data_loader =  torch.utils.data.DataLoader(test_data,batch_size=4, shuffle=True,num_workers=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the pretrained model in ImageNet to extract the feature\n",
    "VGG19_model = torchvision.models.vgg19(pretrained=True)\n",
    "VGG19_model.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            #nn.Linear(4096, num_classes),  # we only neet the 4096-feature extraction net\n",
    "        )\n",
    "\n",
    "# the image restruction network\n",
    "model = IRN.IRN(in_planes=3)\n",
    "# lr=0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "accuracy = []\n",
    "\n",
    "for epoch in tqdm(range(1, n_epochs+1)):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    total_sample = 0\n",
    "    right_sample = 0\n",
    "    \n",
    "    ###################\n",
    "    # 训练集的模型 #\n",
    "    ###################\n",
    "    model.train() #作用是启用batch normalization和drop out\n",
    "    for data, target in train_data_loader:\n",
    "        # clear the gradients of all optimized variables（清除梯度）\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        # (正向传递：通过向模型传递输入来计算预测输出)\n",
    "        output = model(data).to(device)  #（等价于output = model.forward(data).to(device) ）\n",
    "        # calculate the batch loss\n",
    "        extracted_feature_gen = VGG19_model(output)  # 提取reconstaction之后图像的特征\n",
    "        extracted_feature_target = VGG19_model(data)  # 提取原图像的特征\n",
    "        diff = extracted_feature_gen - extracted_feature_target\n",
    "        loss = torch.mean(torch.sum(torch.square(diff),dim=1))\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    ######################    \n",
    "    # 验证集的模型#\n",
    "    ######################\n",
    "\n",
    "    model.eval()  # 验证模型\n",
    "    for data, target in val_data_loader:\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data).to(device)\n",
    "        # calculate the batch loss\n",
    "        extracted_feature_gen = VGG19_model(output)  # 提取reconstaction之后图像的特征\n",
    "        extracted_feature_target = VGG19_model(data)  # 提取原图像的特征\n",
    "        diff = extracted_feature_gen - extracted_feature_target\n",
    "        loss = torch.mean(torch.sum(torch.square(diff),dim=1))\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class(将输出概率转换为预测类)\n",
    "        _, pred = torch.max(output, 1)    \n",
    "        # compare predictions to true label(将预测与真实标签进行比较)\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        # correct = np.squeeze(correct_tensor.to(device).numpy())\n",
    "        total_sample += batch_size\n",
    "        for i in correct_tensor:\n",
    "            if i:\n",
    "                right_sample += 1\n",
    "    print(\"Accuracy:\",100*right_sample/total_sample,\"%\")\n",
    "    accuracy.append(right_sample/total_sample)   \n",
    "\n",
    "    \n",
    "    # 计算平均损失\n",
    "    train_loss = train_loss/len(train_data_loader.sampler)\n",
    "    valid_loss = valid_loss/len(val_data_loader.sampler)\n",
    "        \n",
    "    # 显示训练集与验证集的损失函数 \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    \n",
    "    # 如果验证集损失函数减少，就保存模型。\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "        torch.save(model.state_dict(), 'cheekpoint/cheekpoint1.pt')\n",
    "        valid_loss_min = valid_loss\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f07d5c506dc792c1d17042ce6d63d3539913070c7203ee1d707a2b2ce1ee992d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
